{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bf2a0c",
   "metadata": {},
   "source": [
    "# Neural Network Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24393ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>spend</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>leads</th>\n",
       "      <th>link_clicks</th>\n",
       "      <th>reach</th>\n",
       "      <th>Agency Tiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IL</td>\n",
       "      <td>47.33</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1689</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>63.65</td>\n",
       "      <td>1857</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1737</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OK</td>\n",
       "      <td>32.53</td>\n",
       "      <td>1718</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1527</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SC</td>\n",
       "      <td>32.31</td>\n",
       "      <td>1725</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1645</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>101.13</td>\n",
       "      <td>3745</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3513</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state   spend  Impressions  leads  link_clicks  reach  Agency Tiers\n",
       "0    IL   47.33         1780      0            7   1689           4.0\n",
       "1    NY   63.65         1857      1           10   1737           4.0\n",
       "2    OK   32.53         1718      0            7   1527           4.0\n",
       "3    SC   32.31         1725      1           14   1645           4.0\n",
       "4    CA  101.13         3745      1           28   3513           4.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# # Import and read the csv.\n",
    "# b2 view\n",
    "df = pd.read_csv(\"../ML_Data_&_Preprocessing/b2_df_nonEncoded.csv\", index_col=[0])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563ad288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    21698\n",
       "0    12272\n",
       "Name: leads, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['leads'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "951df0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA    7685\n",
       "TX    4254\n",
       "VA    3239\n",
       "CO    2386\n",
       "FL    1758\n",
       "MI    1655\n",
       "GA    1620\n",
       "NY    1486\n",
       "NC    1050\n",
       "TN     970\n",
       "WA     960\n",
       "NJ     919\n",
       "CT     893\n",
       "OH     842\n",
       "MO     777\n",
       "MN     628\n",
       "IL     605\n",
       "MA     454\n",
       "SC     365\n",
       "OK     365\n",
       "MD     357\n",
       "DC     250\n",
       "SD     246\n",
       "NE     173\n",
       "PA      33\n",
       "Name: state, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check on different state values for testing \n",
    "df['state'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a216bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>spend</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>leads</th>\n",
       "      <th>link_clicks</th>\n",
       "      <th>reach</th>\n",
       "      <th>Agency Tiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>101.13</td>\n",
       "      <td>3745</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3513</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>31.40</td>\n",
       "      <td>1764</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1641</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CA</td>\n",
       "      <td>40.95</td>\n",
       "      <td>2263</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2107</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CA</td>\n",
       "      <td>48.71</td>\n",
       "      <td>2400</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2152</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.52</td>\n",
       "      <td>705</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>672</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33533</th>\n",
       "      <td>CA</td>\n",
       "      <td>77.28</td>\n",
       "      <td>1623</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1455</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33534</th>\n",
       "      <td>CA</td>\n",
       "      <td>11.49</td>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>398</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33535</th>\n",
       "      <td>CA</td>\n",
       "      <td>18.03</td>\n",
       "      <td>576</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>559</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33536</th>\n",
       "      <td>CA</td>\n",
       "      <td>17.27</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>537</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33537</th>\n",
       "      <td>CA</td>\n",
       "      <td>11.81</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7685 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state   spend  Impressions  leads  link_clicks  reach  Agency Tiers\n",
       "4        CA  101.13         3745      1           28   3513           4.0\n",
       "5        CA   31.40         1764      1           30   1641           4.0\n",
       "10       CA   40.95         2263      1           16   2107           4.0\n",
       "17       CA   48.71         2400      1           21   2152           4.0\n",
       "19       CA   18.52          705      1           14    672           4.0\n",
       "...     ...     ...          ...    ...          ...    ...           ...\n",
       "33533    CA   77.28         1623      0           16   1455           NaN\n",
       "33534    CA   11.49          404      0            5    398           NaN\n",
       "33535    CA   18.03          576      0            5    559           NaN\n",
       "33536    CA   17.27          555      0            7    537           NaN\n",
       "33537    CA   11.81          407      0            2    390           NaN\n",
       "\n",
       "[7685 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.loc[df['state']== 'CA']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ff87da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7685 entries, 4 to 33537\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   state         7685 non-null   object \n",
      " 1   spend         7685 non-null   float64\n",
      " 2   Impressions   7685 non-null   int64  \n",
      " 3   leads         7685 non-null   int64  \n",
      " 4   link_clicks   7685 non-null   int64  \n",
      " 5   reach         7685 non-null   int64  \n",
      " 6   Agency Tiers  3175 non-null   float64\n",
      "dtypes: float64(2), int64(4), object(1)\n",
      "memory usage: 480.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac28207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(df2.columns[[0,6]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff396a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7685 entries, 4 to 33537\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   spend        7685 non-null   float64\n",
      " 1   Impressions  7685 non-null   int64  \n",
      " 2   leads        7685 non-null   int64  \n",
      " 3   link_clicks  7685 non-null   int64  \n",
      " 4   reach        7685 non-null   int64  \n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 360.2 KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200565c8",
   "metadata": {},
   "source": [
    "# Split into train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d94906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashi\\AppData\\Local\\Temp\\ipykernel_15460\\3165784757.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  X = df3.drop(['leads'], 1).values\n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = df3['leads'].values\n",
    "X = df3.drop(['leads'], 1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892d91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa1cbb6",
   "metadata": {},
   "source": [
    "# Compile, Train, Evaluate our Model 1 - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05aec29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                150       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 15)                465       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 32        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 650\n",
      "Trainable params: 650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# using multi-layer perceptron (two layers)\n",
    "numInputFeatures = len(X_train[0])\n",
    "\n",
    "# I have X amount of columns\n",
    "# layer1 = input layer, typically equals number of input variables in data\n",
    "layer1 = 30\n",
    "# layer 2 = hidden layer, typically 2/3 of input layer\n",
    "layer2 = 15\n",
    "# layer 3 = hidden layer\n",
    "layer3= 2\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=layer1, \n",
    "                          input_dim=numInputFeatures, \n",
    "                          activation=\"hard_sigmoid\")\n",
    ")\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=layer2, \n",
    "                             activation=\"elu\"))\n",
    "\n",
    "# adding a third layer to increase accuracy \n",
    "nn.add(tf.keras.layers.Dense(units=layer3, \n",
    "                             activation='elu'))\n",
    "\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"hard_sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48845696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every epoch\n",
    "cp_callback = ModelCheckpoint(\n",
    "    # checkpoint directory and file structure defined above\n",
    "    filepath=checkpoint_path,\n",
    "    # notified when checkpoint is being saved to the directory\n",
    "    verbose=1,\n",
    "    # checkpoint files take small space\n",
    "    save_weights_only=True,\n",
    "    # checkpoints saved every epoch\n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74ea1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.5695 - accuracy: 0.7081\n",
      "Epoch 1: saving model to checkpoints\\weights.01.hdf5\n",
      "181/181 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7080\n",
      "Epoch 2/100\n",
      "176/181 [============================>.] - ETA: 0s - loss: 0.5194 - accuracy: 0.7811\n",
      "Epoch 2: saving model to checkpoints\\weights.02.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7803\n",
      "Epoch 3/100\n",
      "177/181 [============================>.] - ETA: 0s - loss: 0.5074 - accuracy: 0.7848\n",
      "Epoch 3: saving model to checkpoints\\weights.03.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7854\n",
      "Epoch 4/100\n",
      "170/181 [===========================>..] - ETA: 0s - loss: 0.4985 - accuracy: 0.7790\n",
      "Epoch 4: saving model to checkpoints\\weights.04.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7786\n",
      "Epoch 5/100\n",
      "154/181 [========================>.....] - ETA: 0s - loss: 0.4953 - accuracy: 0.7778\n",
      "Epoch 5: saving model to checkpoints\\weights.05.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7789\n",
      "Epoch 6/100\n",
      "159/181 [=========================>....] - ETA: 0s - loss: 0.4859 - accuracy: 0.7811\n",
      "Epoch 6: saving model to checkpoints\\weights.06.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7781\n",
      "Epoch 7/100\n",
      "172/181 [===========================>..] - ETA: 0s - loss: 0.4810 - accuracy: 0.7738\n",
      "Epoch 7: saving model to checkpoints\\weights.07.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7744\n",
      "Epoch 8/100\n",
      "158/181 [=========================>....] - ETA: 0s - loss: 0.4744 - accuracy: 0.7761\n",
      "Epoch 8: saving model to checkpoints\\weights.08.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7775\n",
      "Epoch 9/100\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4695 - accuracy: 0.7838\n",
      "Epoch 9: saving model to checkpoints\\weights.09.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7838\n",
      "Epoch 10/100\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.7883\n",
      "Epoch 10: saving model to checkpoints\\weights.10.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7883\n",
      "Epoch 11/100\n",
      "175/181 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.7871\n",
      "Epoch 11: saving model to checkpoints\\weights.11.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7881\n",
      "Epoch 12/100\n",
      "172/181 [===========================>..] - ETA: 0s - loss: 0.4666 - accuracy: 0.7892\n",
      "Epoch 12: saving model to checkpoints\\weights.12.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7893\n",
      "Epoch 13/100\n",
      "165/181 [==========================>...] - ETA: 0s - loss: 0.4661 - accuracy: 0.7905\n",
      "Epoch 13: saving model to checkpoints\\weights.13.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7895\n",
      "Epoch 14/100\n",
      "178/181 [============================>.] - ETA: 0s - loss: 0.4644 - accuracy: 0.7904\n",
      "Epoch 14: saving model to checkpoints\\weights.14.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7909\n",
      "Epoch 15/100\n",
      "172/181 [===========================>..] - ETA: 0s - loss: 0.4650 - accuracy: 0.7894\n",
      "Epoch 15: saving model to checkpoints\\weights.15.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7899\n",
      "Epoch 16/100\n",
      "169/181 [===========================>..] - ETA: 0s - loss: 0.4577 - accuracy: 0.7929\n",
      "Epoch 16: saving model to checkpoints\\weights.16.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7913\n",
      "Epoch 17/100\n",
      "157/181 [=========================>....] - ETA: 0s - loss: 0.4610 - accuracy: 0.7924\n",
      "Epoch 17: saving model to checkpoints\\weights.17.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7913\n",
      "Epoch 18/100\n",
      "177/181 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.7931\n",
      "Epoch 18: saving model to checkpoints\\weights.18.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7928\n",
      "Epoch 19/100\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4602 - accuracy: 0.7913\n",
      "Epoch 19: saving model to checkpoints\\weights.19.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7913\n",
      "Epoch 20/100\n",
      "165/181 [==========================>...] - ETA: 0s - loss: 0.4604 - accuracy: 0.7911\n",
      "Epoch 20: saving model to checkpoints\\weights.20.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7923\n",
      "Epoch 21/100\n",
      "173/181 [===========================>..] - ETA: 0s - loss: 0.4571 - accuracy: 0.7944\n",
      "Epoch 21: saving model to checkpoints\\weights.21.hdf5\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.7944\n",
      "Epoch 22/100\n",
      "174/181 [===========================>..] - ETA: 0s - loss: 0.4558 - accuracy: 0.7947\n",
      "Epoch 22: saving model to checkpoints\\weights.22.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7926\n",
      "Epoch 23/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4549 - accuracy: 0.7954\n",
      "Epoch 23: saving model to checkpoints\\weights.23.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7952\n",
      "Epoch 24/100\n",
      "177/181 [============================>.] - ETA: 0s - loss: 0.4540 - accuracy: 0.7943\n",
      "Epoch 24: saving model to checkpoints\\weights.24.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7946\n",
      "Epoch 25/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.4550 - accuracy: 0.7955\n",
      "Epoch 25: saving model to checkpoints\\weights.25.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7982\n",
      "Epoch 26/100\n",
      "178/181 [============================>.] - ETA: 0s - loss: 0.4513 - accuracy: 0.7974\n",
      "Epoch 26: saving model to checkpoints\\weights.26.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7977\n",
      "Epoch 27/100\n",
      "169/181 [===========================>..] - ETA: 0s - loss: 0.4536 - accuracy: 0.7942\n",
      "Epoch 27: saving model to checkpoints\\weights.27.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7968\n",
      "Epoch 28/100\n",
      "159/181 [=========================>....] - ETA: 0s - loss: 0.4469 - accuracy: 0.8003\n",
      "Epoch 28: saving model to checkpoints\\weights.28.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7984\n",
      "Epoch 29/100\n",
      "177/181 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.7998\n",
      "Epoch 29: saving model to checkpoints\\weights.29.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7991\n",
      "Epoch 30/100\n",
      "158/181 [=========================>....] - ETA: 0s - loss: 0.4542 - accuracy: 0.7977\n",
      "Epoch 30: saving model to checkpoints\\weights.30.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7972\n",
      "Epoch 31/100\n",
      "166/181 [==========================>...] - ETA: 0s - loss: 0.4443 - accuracy: 0.7991\n",
      "Epoch 31: saving model to checkpoints\\weights.31.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7970\n",
      "Epoch 32/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.7975\n",
      "Epoch 32: saving model to checkpoints\\weights.32.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.7970\n",
      "Epoch 33/100\n",
      "177/181 [============================>.] - ETA: 0s - loss: 0.4451 - accuracy: 0.8007\n",
      "Epoch 33: saving model to checkpoints\\weights.33.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8001\n",
      "Epoch 34/100\n",
      "165/181 [==========================>...] - ETA: 0s - loss: 0.4421 - accuracy: 0.8047\n",
      "Epoch 34: saving model to checkpoints\\weights.34.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8020\n",
      "Epoch 35/100\n",
      "159/181 [=========================>....] - ETA: 0s - loss: 0.4427 - accuracy: 0.8035\n",
      "Epoch 35: saving model to checkpoints\\weights.35.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.8024\n",
      "Epoch 36/100\n",
      "181/181 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8011\n",
      "Epoch 36: saving model to checkpoints\\weights.36.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4456 - accuracy: 0.8011\n",
      "Epoch 37/100\n",
      "169/181 [===========================>..] - ETA: 0s - loss: 0.4461 - accuracy: 0.8023\n",
      "Epoch 37: saving model to checkpoints\\weights.37.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8020\n",
      "Epoch 38/100\n",
      "174/181 [===========================>..] - ETA: 0s - loss: 0.4751 - accuracy: 0.7821\n",
      "Epoch 38: saving model to checkpoints\\weights.38.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7831\n",
      "Epoch 39/100\n",
      "161/181 [=========================>....] - ETA: 0s - loss: 0.4522 - accuracy: 0.8010\n",
      "Epoch 39: saving model to checkpoints\\weights.39.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.8025\n",
      "Epoch 40/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4433 - accuracy: 0.8027\n",
      "Epoch 40: saving model to checkpoints\\weights.40.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8025\n",
      "Epoch 41/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.4452 - accuracy: 0.8018\n",
      "Epoch 41: saving model to checkpoints\\weights.41.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8022\n",
      "Epoch 42/100\n",
      "158/181 [=========================>....] - ETA: 0s - loss: 0.4403 - accuracy: 0.8038\n",
      "Epoch 42: saving model to checkpoints\\weights.42.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8008\n",
      "Epoch 43/100\n",
      "169/181 [===========================>..] - ETA: 0s - loss: 0.4418 - accuracy: 0.8009\n",
      "Epoch 43: saving model to checkpoints\\weights.43.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8011\n",
      "Epoch 44/100\n",
      "165/181 [==========================>...] - ETA: 0s - loss: 0.4432 - accuracy: 0.8034\n",
      "Epoch 44: saving model to checkpoints\\weights.44.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8034\n",
      "Epoch 45/100\n",
      "174/181 [===========================>..] - ETA: 0s - loss: 0.4459 - accuracy: 0.8012\n",
      "Epoch 45: saving model to checkpoints\\weights.45.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8037\n",
      "Epoch 46/100\n",
      "154/181 [========================>.....] - ETA: 0s - loss: 0.4508 - accuracy: 0.7979\n",
      "Epoch 46: saving model to checkpoints\\weights.46.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8001\n",
      "Epoch 47/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4457 - accuracy: 0.8027\n",
      "Epoch 47: saving model to checkpoints\\weights.47.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.8029\n",
      "Epoch 48/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4444 - accuracy: 0.8010\n",
      "Epoch 48: saving model to checkpoints\\weights.48.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8018\n",
      "Epoch 49/100\n",
      "175/181 [============================>.] - ETA: 0s - loss: 0.4439 - accuracy: 0.7998\n",
      "Epoch 49: saving model to checkpoints\\weights.49.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8011\n",
      "Epoch 50/100\n",
      "163/181 [==========================>...] - ETA: 0s - loss: 0.4506 - accuracy: 0.7981\n",
      "Epoch 50: saving model to checkpoints\\weights.50.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8005\n",
      "Epoch 51/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.4524 - accuracy: 0.7992\n",
      "Epoch 51: saving model to checkpoints\\weights.51.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8001\n",
      "Epoch 52/100\n",
      "176/181 [============================>.] - ETA: 0s - loss: 0.4440 - accuracy: 0.7999\n",
      "Epoch 52: saving model to checkpoints\\weights.52.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8011\n",
      "Epoch 53/100\n",
      "170/181 [===========================>..] - ETA: 0s - loss: 0.4446 - accuracy: 0.8029\n",
      "Epoch 53: saving model to checkpoints\\weights.53.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8036\n",
      "Epoch 54/100\n",
      "174/181 [===========================>..] - ETA: 0s - loss: 0.4454 - accuracy: 0.8012\n",
      "Epoch 54: saving model to checkpoints\\weights.54.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4446 - accuracy: 0.8011\n",
      "Epoch 55/100\n",
      "175/181 [============================>.] - ETA: 0s - loss: 0.4438 - accuracy: 0.8011\n",
      "Epoch 55: saving model to checkpoints\\weights.55.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8020\n",
      "Epoch 56/100\n",
      "162/181 [=========================>....] - ETA: 0s - loss: 0.4483 - accuracy: 0.8002\n",
      "Epoch 56: saving model to checkpoints\\weights.56.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.8018\n",
      "Epoch 57/100\n",
      "165/181 [==========================>...] - ETA: 0s - loss: 0.4404 - accuracy: 0.8042\n",
      "Epoch 57: saving model to checkpoints\\weights.57.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8017\n",
      "Epoch 58/100\n",
      "171/181 [===========================>..] - ETA: 0s - loss: 0.4443 - accuracy: 0.8004\n",
      "Epoch 58: saving model to checkpoints\\weights.58.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.8008\n",
      "Epoch 59/100\n",
      "171/181 [===========================>..] - ETA: 0s - loss: 0.4453 - accuracy: 0.8045\n",
      "Epoch 59: saving model to checkpoints\\weights.59.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.8032\n",
      "Epoch 60/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4432 - accuracy: 0.8022\n",
      "Epoch 60: saving model to checkpoints\\weights.60.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8018\n",
      "Epoch 61/100\n",
      "171/181 [===========================>..] - ETA: 0s - loss: 0.4447 - accuracy: 0.8030\n",
      "Epoch 61: saving model to checkpoints\\weights.61.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.8024\n",
      "Epoch 62/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.8031\n",
      "Epoch 62: saving model to checkpoints\\weights.62.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8027\n",
      "Epoch 63/100\n",
      "159/181 [=========================>....] - ETA: 0s - loss: 0.4497 - accuracy: 0.8001\n",
      "Epoch 63: saving model to checkpoints\\weights.63.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8027\n",
      "Epoch 64/100\n",
      "170/181 [===========================>..] - ETA: 0s - loss: 0.4399 - accuracy: 0.8048\n",
      "Epoch 64: saving model to checkpoints\\weights.64.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8039\n",
      "Epoch 65/100\n",
      "167/181 [==========================>...] - ETA: 0s - loss: 0.4517 - accuracy: 0.7981\n",
      "Epoch 65: saving model to checkpoints\\weights.65.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7985\n",
      "Epoch 66/100\n",
      "174/181 [===========================>..] - ETA: 0s - loss: 0.4504 - accuracy: 0.8030\n",
      "Epoch 66: saving model to checkpoints\\weights.66.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.8027\n",
      "Epoch 67/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.4409 - accuracy: 0.8037\n",
      "Epoch 67: saving model to checkpoints\\weights.67.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8029\n",
      "Epoch 68/100\n",
      "163/181 [==========================>...] - ETA: 0s - loss: 0.4436 - accuracy: 0.8021\n",
      "Epoch 68: saving model to checkpoints\\weights.68.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8020\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/181 [=========================>....] - ETA: 0s - loss: 0.4481 - accuracy: 0.8014\n",
      "Epoch 69: saving model to checkpoints\\weights.69.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8015\n",
      "Epoch 70/100\n",
      "170/181 [===========================>..] - ETA: 0s - loss: 0.4433 - accuracy: 0.8024\n",
      "Epoch 70: saving model to checkpoints\\weights.70.hdf5\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.8032\n",
      "Epoch 71/100\n",
      "168/181 [==========================>...] - ETA: 0s - loss: 0.4420 - accuracy: 0.7987\n",
      "Epoch 71: saving model to checkpoints\\weights.71.hdf5\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.4418 - accuracy: 0.7996\n",
      "Epoch 72/100\n",
      "179/181 [============================>.] - ETA: 0s - loss: 0.4427 - accuracy: 0.8012\n",
      "Epoch 72: saving model to checkpoints\\weights.72.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8015\n",
      "Epoch 73/100\n",
      "163/181 [==========================>...] - ETA: 0s - loss: 0.4523 - accuracy: 0.7995\n",
      "Epoch 73: saving model to checkpoints\\weights.73.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8015\n",
      "Epoch 74/100\n",
      "160/181 [=========================>....] - ETA: 0s - loss: 0.4408 - accuracy: 0.8027\n",
      "Epoch 74: saving model to checkpoints\\weights.74.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8025\n",
      "Epoch 75/100\n",
      "158/181 [=========================>....] - ETA: 0s - loss: 0.4414 - accuracy: 0.8020\n",
      "Epoch 75: saving model to checkpoints\\weights.75.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8024\n",
      "Epoch 76/100\n",
      "173/181 [===========================>..] - ETA: 0s - loss: 0.4402 - accuracy: 0.8031\n",
      "Epoch 76: saving model to checkpoints\\weights.76.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8020\n",
      "Epoch 77/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.4448 - accuracy: 0.8016\n",
      "Epoch 77: saving model to checkpoints\\weights.77.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8013\n",
      "Epoch 78/100\n",
      "169/181 [===========================>..] - ETA: 0s - loss: 0.4443 - accuracy: 0.8005\n",
      "Epoch 78: saving model to checkpoints\\weights.78.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8008\n",
      "Epoch 79/100\n",
      "176/181 [============================>.] - ETA: 0s - loss: 0.4460 - accuracy: 0.8006\n",
      "Epoch 79: saving model to checkpoints\\weights.79.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4457 - accuracy: 0.8013\n",
      "Epoch 80/100\n",
      "163/181 [==========================>...] - ETA: 0s - loss: 0.4429 - accuracy: 0.8050\n",
      "Epoch 80: saving model to checkpoints\\weights.80.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8027\n",
      "Epoch 81/100\n",
      "167/181 [==========================>...] - ETA: 0s - loss: 0.4424 - accuracy: 0.8063\n",
      "Epoch 81: saving model to checkpoints\\weights.81.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8053\n",
      "Epoch 82/100\n",
      "159/181 [=========================>....] - ETA: 0s - loss: 0.4445 - accuracy: 0.8005\n",
      "Epoch 82: saving model to checkpoints\\weights.82.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.8013\n",
      "Epoch 83/100\n",
      "173/181 [===========================>..] - ETA: 0s - loss: 0.4454 - accuracy: 0.8009\n",
      "Epoch 83: saving model to checkpoints\\weights.83.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8011\n",
      "Epoch 84/100\n",
      "154/181 [========================>.....] - ETA: 0s - loss: 0.5232 - accuracy: 0.7470\n",
      "Epoch 84: saving model to checkpoints\\weights.84.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.7545\n",
      "Epoch 85/100\n",
      "176/181 [============================>.] - ETA: 0s - loss: 0.4456 - accuracy: 0.8020\n",
      "Epoch 85: saving model to checkpoints\\weights.85.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8011\n",
      "Epoch 86/100\n",
      "175/181 [============================>.] - ETA: 0s - loss: 0.4420 - accuracy: 0.8018\n",
      "Epoch 86: saving model to checkpoints\\weights.86.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8020\n",
      "Epoch 87/100\n",
      "170/181 [===========================>..] - ETA: 0s - loss: 0.4433 - accuracy: 0.8004\n",
      "Epoch 87: saving model to checkpoints\\weights.87.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8025\n",
      "Epoch 88/100\n",
      "155/181 [========================>.....] - ETA: 0s - loss: 0.4475 - accuracy: 0.7986\n",
      "Epoch 88: saving model to checkpoints\\weights.88.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7996\n",
      "Epoch 89/100\n",
      "166/181 [==========================>...] - ETA: 0s - loss: 0.4411 - accuracy: 0.8018\n",
      "Epoch 89: saving model to checkpoints\\weights.89.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8008\n",
      "Epoch 90/100\n",
      "162/181 [=========================>....] - ETA: 0s - loss: 0.4403 - accuracy: 0.8032\n",
      "Epoch 90: saving model to checkpoints\\weights.90.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.8031\n",
      "Epoch 91/100\n",
      "161/181 [=========================>....] - ETA: 0s - loss: 0.4389 - accuracy: 0.8049\n",
      "Epoch 91: saving model to checkpoints\\weights.91.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8037\n",
      "Epoch 92/100\n",
      "162/181 [=========================>....] - ETA: 0s - loss: 0.4421 - accuracy: 0.8032\n",
      "Epoch 92: saving model to checkpoints\\weights.92.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8017\n",
      "Epoch 93/100\n",
      "166/181 [==========================>...] - ETA: 0s - loss: 0.4390 - accuracy: 0.8038\n",
      "Epoch 93: saving model to checkpoints\\weights.93.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8013\n",
      "Epoch 94/100\n",
      "173/181 [===========================>..] - ETA: 0s - loss: 0.4427 - accuracy: 0.8017\n",
      "Epoch 94: saving model to checkpoints\\weights.94.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.8025\n",
      "Epoch 95/100\n",
      "157/181 [=========================>....] - ETA: 0s - loss: 0.4449 - accuracy: 0.7990\n",
      "Epoch 95: saving model to checkpoints\\weights.95.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8013\n",
      "Epoch 96/100\n",
      "180/181 [============================>.] - ETA: 0s - loss: 0.4412 - accuracy: 0.7998\n",
      "Epoch 96: saving model to checkpoints\\weights.96.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.7998\n",
      "Epoch 97/100\n",
      "178/181 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.8032\n",
      "Epoch 97: saving model to checkpoints\\weights.97.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8025\n",
      "Epoch 98/100\n",
      "157/181 [=========================>....] - ETA: 0s - loss: 0.4454 - accuracy: 0.8025\n",
      "Epoch 98: saving model to checkpoints\\weights.98.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8025\n",
      "Epoch 99/100\n",
      "171/181 [===========================>..] - ETA: 0s - loss: 0.4426 - accuracy: 0.8030\n",
      "Epoch 99: saving model to checkpoints\\weights.99.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8018\n",
      "Epoch 100/100\n",
      "164/181 [==========================>...] - ETA: 0s - loss: 0.4435 - accuracy: 0.8047\n",
      "Epoch 100: saving model to checkpoints\\weights.100.hdf5\n",
      "181/181 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8032\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a833b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 1s - loss: 0.4750 - accuracy: 0.7789 - 533ms/epoch - 9ms/step\n",
      "Loss: 0.47504448890686035, Accuracy: 0.7788761854171753\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "\n",
    "# when brand 1, all states, accuracy = 36%\n",
    "# when brand 2, all states, accuracy = 36%\n",
    "# when brand 3, all states, accuracy = 36%\n",
    "\n",
    "# CA = .80%\n",
    "# FL = .84%\n",
    "# TX = .84%\n",
    "# VA = .78%\n",
    "# CO = .71%\n",
    "# MI = .79%\n",
    "# GA = .84%\n",
    "# NY = .85%\n",
    "# NC = .85%\n",
    "# TN = .75%\n",
    "# WA = .80%\n",
    "# NJ = .78%\n",
    "# CT = .82%\n",
    "# OH = .82%\n",
    "# MO = .91%\n",
    "# MN = .77%\n",
    "# IL = .82%\n",
    "# MA = .85%\n",
    "# SC = .63%\n",
    "# OK = .72%\n",
    "# MD = .89%\n",
    "# DC = .84%\n",
    "# SD = .94%\n",
    "# NE = .86%\n",
    "# PA = 100%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab0f4c8",
   "metadata": {},
   "source": [
    "### B2 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd2e09",
   "metadata": {},
   "source": [
    "#### B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0349ceee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'State': ['CA',\n",
       "  'FL',\n",
       "  'TX',\n",
       "  'VA',\n",
       "  'CO',\n",
       "  'MI',\n",
       "  'GA',\n",
       "  'NY',\n",
       "  'NC',\n",
       "  'TN',\n",
       "  'WA',\n",
       "  'NJ',\n",
       "  'CT',\n",
       "  'OH',\n",
       "  'MO',\n",
       "  'MN',\n",
       "  'IL',\n",
       "  'MA',\n",
       "  'SC',\n",
       "  'OK',\n",
       "  'MD',\n",
       "  'DC',\n",
       "  'DC',\n",
       "  'SD',\n",
       "  'NE',\n",
       "  'PA'],\n",
       " 'Predictive Accuracy': [0.8,\n",
       "  0.84,\n",
       "  0.84,\n",
       "  0.78,\n",
       "  0.71,\n",
       "  0.79,\n",
       "  0.84,\n",
       "  0.85,\n",
       "  0.85,\n",
       "  0.75],\n",
       " 'Notes': ['N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A',\n",
       "  'N/A']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_results_b2 = {\n",
    "        'State': ['CA', 'FL', 'TX', 'VA', 'CO', 'MI', 'GA', 'NY', 'NC', 'TN', 'WA', 'NJ', 'CT', 'OH', 'MO', 'MN', 'IL', 'MA', 'SC', 'OK', 'MD', 'DC', 'DC', 'SD', 'NE', 'PA'],\n",
    "        'Predictive Accuracy': [.80, .84, .84, .78, .71, .79, .84, .85, .85, .75  ],\n",
    "        'Notes': ['N/A', 'N/A', 'N/A', 'N/A','N/A','N/A','N/A','N/A','N/A','N/A' ]}\n",
    "data_results_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d213644",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create the new df to display brand, state, and model accuracy \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_results_b2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_results_b2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_results_b2\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# create the new df to display brand, state, and model accuracy \n",
    "df_results_b2 = pd.DataFrame(data_results_b2)\n",
    "df_results_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export the model to HDF5 file\n",
    "# nn.save(\"AlphabetSoupCharity_optimization.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
