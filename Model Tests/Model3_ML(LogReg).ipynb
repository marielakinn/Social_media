{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bf2a0c",
   "metadata": {},
   "source": [
    "### Logistic Reg Model - Binary Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24393ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import and read the csv.\n",
    "# # b1 view\n",
    "# df = pd.read_csv('ca_b2_df.csv', index_col=[0])\n",
    "# df.head()\n",
    "\n",
    "# b2 view\n",
    "df = pd.read_csv('ca_b2_df.csv', index_col=[0])\n",
    "df.head()\n",
    "\n",
    "# # b3 view\n",
    "# df = pd.read_csv('ca_b2_df.csv', index_col=[0])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f37b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6887eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight the features differently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0969729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps: \n",
    "# create the model with LogisticRegression()\n",
    "# train the model with model.fit()\n",
    "# make predictions with model.predict()\n",
    "# validate with accuracy_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f2555",
   "metadata": {},
   "source": [
    "### Hyperparam check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logModel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324dcf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [\n",
    "#     {'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#     'C': np.logspace(-4,4,20),\n",
    "#     'solver': ['lbfgs', 'newton-cg', 'liblinear', 'sag', 'saga'],\n",
    "#     'max_iter': [100,1000,2500,5000]}\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0439c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test for most optimal params \n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# clf = GridSearchCV(logModel, param_grid = param_grid, cv=3, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b06215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_clf.best_estimator_\n",
    "# shows that I need a penalty of l1, solver type saga, and c value of .0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a059b4",
   "metadata": {},
   "source": [
    "### Seperate features, x and target, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f50d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = df2[\"leads\"]\n",
    "# X = df2.drop(columns=\"leads\")\n",
    "\n",
    "# or CA option\n",
    "y = df2[\"leads\"]\n",
    "X = df2.drop(columns=\"leads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200565c8",
   "metadata": {},
   "source": [
    "### Split into train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c93b2",
   "metadata": {},
   "source": [
    "### Create Log Reg Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4557dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit the params as needed\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='saga',\n",
    "                                C=0.0001,\n",
    "                                max_iter=500,\n",
    "                                random_state=1,\n",
    "                                class_weight='balanced',\n",
    "                               multi_class='auto', \n",
    "                               penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39228d9a",
   "metadata": {},
   "source": [
    "### Fit/train or model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d697df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66725ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757af85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "# https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "importance = classifier.coef_\n",
    "print(importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5564d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "#     print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73802c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot feature importance\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae45273",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2f57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396dba5",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d09a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5987c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "# TP = 0\n",
    "# FP = 0\n",
    "# FN = 17,460\n",
    "# TN = 21,958\n",
    "\n",
    "# precision = TP/(TP+FP), in this case a precision of 0 means what?\n",
    "# sensitivity = TP/(TP+FN), in this case a score of 0 means what? = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "### note: \n",
    "# ytest are the outcomes, either yes or no on leads column target \n",
    "# y_pred are the predictions\n",
    "# do we read the accuracy score as 56% on predictions as a lead? \n",
    "# F1 = harmonic mean, takes sensitivity and precision = .72 here means what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53943f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef9835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
