{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bf2a0c",
   "metadata": {},
   "source": [
    "### Logistic Reg Model - Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24393ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>spend</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>leads</th>\n",
       "      <th>State Tiers</th>\n",
       "      <th>Agency Tiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770</td>\n",
       "      <td>7.28</td>\n",
       "      <td>427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>771</td>\n",
       "      <td>13.32</td>\n",
       "      <td>1042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>772</td>\n",
       "      <td>10.11</td>\n",
       "      <td>337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>773</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>774</td>\n",
       "      <td>7.35</td>\n",
       "      <td>379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  spend  Impressions  leads  State Tiers  Agency Tiers\n",
       "0         770   7.28          427    0.0            4             4\n",
       "1         771  13.32         1042    1.0            4             4\n",
       "2         772  10.11          337    0.0            4             4\n",
       "3         773   0.00            0    1.0            4             4\n",
       "4         774   7.35          379    1.0            4             4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Import and read the csv.\n",
    "df = pd.read_csv('model_df1_official.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e19524b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157672 entries, 0 to 157671\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   Unnamed: 0    157672 non-null  int64  \n",
      " 1   spend         157672 non-null  float64\n",
      " 2   Impressions   157672 non-null  int64  \n",
      " 3   leads         157672 non-null  float64\n",
      " 4   State Tiers   157672 non-null  int64  \n",
      " 5   Agency Tiers  157672 non-null  int64  \n",
      "dtypes: float64(2), int64(4)\n",
      "memory usage: 7.2 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps: \n",
    "# create the model with LogisticRegression()\n",
    "# train the model with model.fit()\n",
    "# make predictions with model.predict()\n",
    "# validate with accuracy_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82fc27",
   "metadata": {},
   "source": [
    "### Seperate features, x and target, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191467c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"leads\"]\n",
    "X = df.drop(columns=\"leads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200565c8",
   "metadata": {},
   "source": [
    "### Split into train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d94906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118254, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e142e3a",
   "metadata": {},
   "source": [
    "### Create Log Reg Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3534ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66e9d6",
   "metadata": {},
   "source": [
    "### Fit/train or model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52306043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26862c8",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4471153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction  Actual\n",
       "0          1.0     1.0\n",
       "1          1.0     1.0\n",
       "2          1.0     0.0\n",
       "3          1.0     0.0\n",
       "4          1.0     0.0\n",
       "5          1.0     1.0\n",
       "6          1.0     1.0\n",
       "7          1.0     1.0\n",
       "8          1.0     1.0\n",
       "9          1.0     0.0\n",
       "10         1.0     0.0\n",
       "11         1.0     0.0\n",
       "12         1.0     1.0\n",
       "13         1.0     1.0\n",
       "14         1.0     1.0\n",
       "15         1.0     1.0\n",
       "16         1.0     0.0\n",
       "17         1.0     1.0\n",
       "18         1.0     1.0\n",
       "19         1.0     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26cb416",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0913727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5570551524684154\n"
     ]
    }
   ],
   "source": [
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e2faae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 17460]\n",
      " [    0 21958]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "# TP = 0\n",
    "# FP = 0\n",
    "# FN = 17,460\n",
    "# TN = 21,958\n",
    "\n",
    "# precision = TP/(TP+FP), in this case a precision of 0 means what?\n",
    "# sensitivity = TP/(TP+FN), in this case a score of 0 means what? = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934ce3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     17460\n",
      "         1.0       0.56      1.00      0.72     21958\n",
      "\n",
      "    accuracy                           0.56     39418\n",
      "   macro avg       0.28      0.50      0.36     39418\n",
      "weighted avg       0.31      0.56      0.40     39418\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dia78039\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dia78039\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dia78039\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "### note: \n",
    "# ytest are the outcomes, either yes or no on leads column target \n",
    "# y_pred are the predictions\n",
    "# do we read the accuracy score as 56% on predictions as a lead? \n",
    "# F1 = harmonic mean, takes sensitivity and precision = .72 here means what?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
