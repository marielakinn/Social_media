{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bf2a0c",
   "metadata": {},
   "source": [
    "### Logistic Reg Model - Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24393ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Import and read the csv.\n",
    "# # b1 view\n",
    "# df = pd.read_csv('ca_b2_df.csv', index_col=[0])\n",
    "# df.head()\n",
    "\n",
    "# b2 view\n",
    "df = pd.read_csv('ca_b2_df.csv', index_col=[0])\n",
    "df.head()\n",
    "\n",
    "# # b3 view\n",
    "# df = pd.read_csv('ca_b2_df.csv', index_col=[0])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6957a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps: \n",
    "# create the model with LogisticRegression()\n",
    "# train the model with model.fit()\n",
    "# make predictions with model.predict()\n",
    "# validate with accuracy_score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82fc27",
   "metadata": {},
   "source": [
    "### Seperate features, x and target, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191467c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"leads\"]\n",
    "X = df.drop(columns=\"leads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200565c8",
   "metadata": {},
   "source": [
    "### Split into train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d94906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e142e3a",
   "metadata": {},
   "source": [
    "### Create Log Reg Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534ff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66e9d6",
   "metadata": {},
   "source": [
    "### Fit/train or model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52306043",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26862c8",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4471153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26cb416",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0913727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "# TP = 0\n",
    "# FP = 0\n",
    "# FN = 17,460\n",
    "# TN = 21,958\n",
    "\n",
    "# precision = TP/(TP+FP), in this case a precision of 0 means what?\n",
    "# sensitivity = TP/(TP+FN), in this case a score of 0 means what? = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ce3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "### note: \n",
    "# ytest are the outcomes, either yes or no on leads column target \n",
    "# y_pred are the predictions\n",
    "# do we read the accuracy score as 56% on predictions as a lead? \n",
    "# F1 = harmonic mean, takes sensitivity and precision = .72 here means what?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
